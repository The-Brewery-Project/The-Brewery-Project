# -*- coding: utf-8 -*-
"""the_brewery_project_reduced models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Moh1bL1r6TULxAu2h7-w929C2Jwv3OZa
"""

#Goal: to identify the best model to classify rank by using the key city features:
#College Town, Number of National Parks, Number of Ski Resorts,
#Tech Hub and Major City

#Load packages
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

#Call Data:
city_df = pd.read_csv('../data/city_level.csv')

#Reduce Dataframe to required columns
reduced_model_df = city_df[["custom_ranked", "total population","college_town",
                            "tech_city", "major_city","state_national_park_count","ski_resort_count"]]

reduced_model_df = reduced_model_df[reduced_model_df["total population"]>0] #Remove null populations

reduced_model_df = reduced_model_df.astype(int)
reduced_model_df.rename({'custom_ranked':'ranked'}, inplace=True, axis=1)
#reduced_model_df.info()

#Determine test and training sets
X  = reduced_model_df[["total population","college_town","tech_city",
                                       "major_city","state_national_park_count","ski_resort_count"]]
y = reduced_model_df["ranked"]

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 71)

#print(y_train.value_counts(normalize = True))
#print(y_test.value_counts(normalize = True))
#Note unbalanced data: Tried Oversampling, did not help models

#Set up data frame to catch results
result_measures = ['accuracy', 'precision', 'recall', 'f1', 'model']
round_1_results = pd.DataFrame(columns=result_measures)

#Method 1: Decision Tree

#build model
clf = DecisionTreeClassifier().fit(X_train, y_train)
#Predict rank
y_pred = clf.predict(X_test)

#Review performance
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')
results = {'accuracy': accuracy,
               'precision': precision,
               'recall': recall,
               'f1': f1,
               'model': 'Decision Tree Classification'}
results = pd.DataFrame([results])
round_1_results = pd.concat([round_1_results, results], ignore_index=True)

#Method 2: Logistic Regression

#Build Model
clf = LogisticRegression(max_iter=10000).fit(X_train, y_train)
#Predict Rank
y_pred = clf.predict(X_test)

#Review performance
accuracy = accuracy_score(y_test,y_pred)
precision = precision_score(y_test,y_pred, average='weighted')
recall = recall_score(y_test,y_pred, average='weighted')
f1 = f1_score(y_test,y_pred, average='weighted')
results = {'accuracy': accuracy,
               'precision': precision,
               'recall': recall,
               'f1': f1,
               'model': 'Logistic Regression'}
clf_results = pd.DataFrame([results])
round_1_results = pd.concat([round_1_results, clf_results], ignore_index=True)

#Method 3: k-Nearest Neighbors

#Build Model
clf = KNeighborsClassifier().fit(X_train,y_train)
#Predict Rank
y_pred = clf.predict(X_test)

#Review performance
accuracy = accuracy_score(y_test,y_pred)
precision = precision_score(y_test,y_pred, average='weighted')
recall = recall_score(y_test,y_pred, average='weighted')
f1 = f1_score(y_test,y_pred, average='weighted')
results = {'accuracy': accuracy,
               'precision': precision,
               'recall': recall,
               'f1': f1,
               'model': 'k Nearest Neighbors'}
clf_results = pd.DataFrame([results])
round_1_results = pd.concat([round_1_results, clf_results], ignore_index=True)

#Method 4: SVM

#Build Model
clf = SVC().fit(X_train, y_train)
#Predict Rank
y_pred = clf.predict(X_test)

#Review performance
accuracy = accuracy_score(y_test,y_pred)
precision = precision_score(y_test,y_pred, average='weighted')
recall = recall_score(y_test,y_pred, average='weighted')
f1 = f1_score(y_test,y_pred, average='weighted')
results = {'accuracy': accuracy,
               'precision': precision,
               'recall': recall,
               'f1': f1,
               'model': 'SVM'}
clf_results = pd.DataFrame([results])
round_1_results = pd.concat([round_1_results, clf_results], ignore_index=True)

#Method 5: Naive Bayes

#Build Model
clf = GaussianNB().fit(X_train, y_train)
# Predict Rank
y_pred = clf.predict(X_test)

#Review performance
accuracy = accuracy_score(y_test,y_pred)
precision = precision_score(y_test,y_pred, average='weighted')
recall = recall_score(y_test,y_pred, average='weighted')
f1 = f1_score(y_test,y_pred, average='weighted')
results = {'accuracy': accuracy,
               'precision': precision,
               'recall': recall,
               'f1': f1,
               'model': 'Naive Bayes'}
clf_results = pd.DataFrame([results])
round_1_results = pd.concat([round_1_results, clf_results], ignore_index=True)

#Method 6: Linear Discriminant
#Build Model
clf = LinearDiscriminantAnalysis().fit(X_train, y_train)
# Predict Rank
y_pred = clf.predict(X_test)

#Review performance
accuracy = accuracy_score(y_test,y_pred)
precision = precision_score(y_test,y_pred, average='weighted')
recall = recall_score(y_test,y_pred, average='weighted')
f1 = f1_score(y_test,y_pred, average='weighted')
results = {'accuracy': accuracy,
               'precision': precision,
               'recall': recall,
               'f1': f1,
               'model': 'Linear Discriminant'}
clf_results = pd.DataFrame([results])
round_1_results = pd.concat([round_1_results, clf_results], ignore_index=True)
round_1_results.sort_values("f1", ascending = False)

# export round 1 results for website - commented out post script run
round_1_results.to_csv('../data/reduced_model_round1_results.csv', index = False)

#Best Performing Base Models: SVM, Naive Bayes, Linear Discriminant
#Fine tune these three models to see which is best

#Build place to store results
#Fine tuning:
result_columns = ['Accuracy', 'Precision', 'Recall', 'F1', 'Model']
final_model_results = pd.DataFrame(columns=result_columns)

#use GridSearchCV to compare different parameters on the models

#Finetuning Naive Bayes Model
#GaussianNB parameters to run through
gaussNB_parameters = {'var_smoothing':(0.000000001,0.000001, 0.001)}
# create gridsearchcv object
gaussNB_clf_hyper = GridSearchCV(GaussianNB(), gaussNB_parameters,n_jobs =1)
# train the model
gaussNB_clf_hyper.fit(X_train, y_train)

# results
gaussNB_clf_hyper_results = pd.DataFrame(gaussNB_clf_hyper.cv_results_)
#gaussNB_clf_hyper_results

#Best Performance:
#gaussNB_clf_hyper.best_params_
#{'var_smoothing': 1e-06}

# Naive Bayes with best params
clf = GaussianNB(**gaussNB_clf_hyper.best_params_).fit(X_train, y_train)
# prediction
y_pred = clf.predict(X_test)
# results (will set average to weighted for multiclass vs binary)
#Review performance
accuracy = accuracy_score(y_test,y_pred)
precision = precision_score(y_test,y_pred, average='weighted')
recall = recall_score(y_test,y_pred, average='weighted')
f1 = f1_score(y_test,y_pred, average='weighted')
results = {'Accuracy': accuracy,
               'Precision': precision,
               'Recall': recall,
               'F1': f1,
               'Model': 'Naive Bayes'}
clf_results = pd.DataFrame([results])
final_model_results = pd.concat([final_model_results, clf_results], ignore_index=True)

#Finetuning Linear Discriminant Model
#LinearDisc parameters to run through
linearDisc_parameters = {'solver':('svd', 'lsqr', 'eigen'),
                         'shrinkage': ('auto', 0,0.5, 1,'None')}
# create gridsearchcv object
linearDisc_clf_hyper = GridSearchCV(LinearDiscriminantAnalysis(), linearDisc_parameters,n_jobs =1)
# train the model
linearDisc_clf_hyper.fit(X_train, y_train)

# results
linearDisc_clf_hyper_results = pd.DataFrame(linearDisc_clf_hyper.cv_results_)
#linearDisc_clf_hyper_results

#Best Performance:
#linearDisc_clf_hyper.best_params_
#{'shrinkage': 0.5, 'solver': 'lsqr'}

# Linear Discriminant with best params
clf = LinearDiscriminantAnalysis(**linearDisc_clf_hyper.best_params_).fit(X_train, y_train)
# prediction
y_pred = clf.predict(X_test)
# results (will set average to weighted for multiclass vs binary)
#Review performance
accuracy = accuracy_score(y_test,y_pred)
precision = precision_score(y_test,y_pred, average='weighted')
recall = recall_score(y_test,y_pred, average='weighted')
f1 = f1_score(y_test,y_pred, average='weighted')
results = {'Accuracy': accuracy,
               'Precision': precision,
               'Recall': recall,
               'F1': f1,
               'Model': 'Linear Discriminant'}
clf_results = pd.DataFrame([results])
final_model_results = pd.concat([final_model_results, clf_results], ignore_index=True)

#Finetuning SVM Model
#SVM parameters to run through
SVM_parameters = {'kernel': ('linear', 'poly', 'rbf','sigmoid'),
              'degree': (2,3,4),
              'class_weight': (None, 'balanced')}
# create gridsearchcv object
SVM_clf_hyper = GridSearchCV(SVC(max_iter = 10000), SVM_parameters,n_jobs =1)
# train the model
SVM_clf_hyper.fit(X_train, y_train)

# results
SVM_clf_hyper_results = pd.DataFrame(SVM_clf_hyper.cv_results_)
#SVM_clf_hyper_results

#Best Performance:
#SVM_clf_hyper.best_params_
#{'class_weight': None, 'degree': 2, 'kernel': 'rbf'}

# Linear Discriminant with best params
clf = SVC(**SVM_clf_hyper.best_params_).fit(X_train, y_train)
# prediction
y_pred = clf.predict(X_test)
# results (will set average to weighted for multiclass vs binary)
#Review performance
accuracy = accuracy_score(y_test,y_pred)
precision = precision_score(y_test,y_pred, average='weighted')
recall = recall_score(y_test,y_pred, average='weighted')
f1 = f1_score(y_test,y_pred, average='weighted')
results = {'Accuracy': accuracy,
               'Precision': precision,
               'Recall': recall,
               'F1': f1,
               'Model': 'SVM'}
clf_results = pd.DataFrame([results])
final_model_results = pd.concat([final_model_results, clf_results], ignore_index=True)

final_model_results.sort_values("F1", ascending = False)
# export final model results for website - commented out post script run
final_model_results.to_csv('../data/reduced_model_final_results.csv', index = False)
