---
title: "Data Exploration"
---

This page features our process for gathering, cleaning, and providing an initial exploratory analysis of the data used.

# Open Brewery DB

The driving dataset of our project, this was pulled via API from the Open Brewery DB [website](https://www.openbrewerydb.org/).

## Data Cleaning

### Initial Dataset

![](images/data_exploration/open-brewery-db-a.png)

### Cleaning Process

We first reviewed the countries available, and found cleaning and slicing on the country name column were warranted.

![](images/data_exploration/open-brewery-db-1.png)

After applying a strip and lowercase on the country column, we filtered just for the United States, and then examined the null values.

There are quite a few missing rows in **address_1** column, and even some incomplete addresses at that. With the the completeness of the **city**, **state**, and **postal_code**, we can disregaard the other address columns and drop all three.

Additionally, **state** is identical to **state_province**. We can remove the duplicate columns.

After removing  nonessential rows and columns, we applied the strip and lowercase procedure on the remaining columns, and then reexamined the null values.

![](images/data_exploration/open-brewery-db-2.png)

We decided to move forward with this data, and potentially massage any **longitude/latitude** data issues later. Keeping the column could be useful later. The **phone** and **website_url** columns will likely be irrelevant, but they may prove useful in the future so retained those columns.

### Cleaned Dataset

![](images/data_exploration/open-brewery-db-b.png)

## Data Exploration

Our initial observation of the data is that we are dealing almost primarily with categorical values.

![](images/data_exploration/open-brewery-db-3.png)

The latitudes and longitudes are *float* numeric values, however, they're more for mapping so less meaningful to analyze other than geographically.

One method we could use to gather some numerical essence from this is to analyze the categories (i.e. counts of breweries per state or per city, types of breweries per state or per city, etc.).

Let's take a look at how numerous the overall categories are.

### Categorical Spread

![](images/data_exploration/open-brewery-db-4.png)


A useful starting point in the visualizations would be to break down the spread of brewery types and find the top-5 and bottom-5 for brewery counts by state, leading into some heat maps of these spreads.

### Brewery Type

![](images/data_exploration/open-brewery-db-5.png)

The overwhelming amount of breweries are classified as *micro* breweries, and that the bottom 5 breweries have such small counts that they don't even appear on the plot. Another important observation is that *closed* breweries are somewhat significant in that they appear as a bar on the plot. *Closed* could become a factor in later models, so we decided to leave these data points in.

### States with the Most and Least Breweries

::: columns
::: {.column width="45%"}

![](images/data_exploration/open-brewery-db-6.png)
:::

::: {.column width="10%"}
:::

::: {.column width="45%"}
![](images/data_exploration/open-brewery-db-7.png)
:::
:::

From this initial glance, we can see what that the breweries per state varies wildly.

### Geographical Representations

We can create an interactive map. *Note that just the dataset of brewery counts by states will be uploaded to promote efficiency.*

**Import libraries:**

```{python}
import numpy as np
import pandas as pd
import plotly.express as px
breweries_by_state = pd.read_csv('data/brewery-count-by-state.csv')
```

**Interactive Plot**

```{python}
# geographical representations
fig = px.choropleth(breweries_by_state,
                    locationmode = 'USA-states',
                    locations = 'State',
                    scope = 'usa',
                    color = 'Count',
                    color_continuous_scale = 'Viridis_r',
                    title = 'Breweries by State')
fig.show()
```
